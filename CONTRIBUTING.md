# ü§ù Guia de Contribui√ß√£o, Reprodutibilidade e Infer√™ncia

Bem-vindo ao manual t√©cnico e arquitet√≥nico da minha solu√ß√£o para a dete√ß√£o de fraudes financeiras. Concebi este guia com um objetivo claro: garantir **100% de reprodutibilidade** e demonstrar que o projeto transcende a simples cria√ß√£o de um modelo de *Machine Learning*. 

Aqui, detalho como apliquei boas pr√°ticas de engenharia de *software*, segrega√ß√£o rigorosa de dados e um *pipeline* preparado n√£o apenas para o Kaggle, mas para infer√™ncia de novos dados num ambiente de produ√ß√£o real.

---

##  1. Configura√ß√£o do Ambiente Local (Reprodutibilidade: 5/5)

Para evitar os cl√°ssicos problemas de depend√™ncias cruzadas e garantir que a aplica√ß√£o funciona perfeitamente em qualquer m√°quina, estruturei o projeto com recurso a ambientes virtuais isolados.

**Passo 1: Clonar o reposit√≥rio**
```bash
git clone [https://github.com/willianrupert/teste.git](https://github.com/willianrupert/teste.git)
cd teste
```

**Passo 2: Criar e ativar o ambiente virtual**
A utiliza√ß√£o de um *venv* garante que as vers√µes do XGBoost, CatBoost e SHAP n√£o entram em conflito com as bibliotecas do teu sistema.
```bash
# Em sistemas Linux/macOS:
python3 -m venv venv
source venv/bin/activate

# Em sistemas Windows:
python -m venv venv
venv\Scripts\activate
```

**Passo 3: Instalar as depend√™ncias rigorosamente mapeadas**
```bash
pip install -r requirements.txt
```

---

##  2. Arquitetura e Segrega√ß√£o de Ficheiros (Qualidade de Engenharia: 5/5)

A separa√ß√£o de responsabilidades √© o cora√ß√£o deste projeto. Evitei deliberadamente *notebooks* monol√≠ticos, optando por uma estrutura modular digna de um sistema *end-to-end*.

* **`/data/`**: Pasta reservada aos ficheiros `train.csv` e `test.csv`. *(Nota: Esta pasta est√° no `.gitignore` para proteger a integridade dos dados originais e cumprir regras de privacidade).*
* **`/src/`**: O motor da aplica√ß√£o.
  * `preprocessing.py`: Centraliza as transforma√ß√µes n√£o-lineares, as rota√ß√µes geom√©tricas (`V4_minus_V14`) e o *RobustScaler*. Esta modularidade permite que a mesma transforma√ß√£o seja aplicada a dados futuros de infer√™ncia sem reescrever c√≥digo.
  * `model.py`: Encapsula a arquitetura complexa do *Stacking Ensemble*. √â aqui que a Otimiza√ß√£o Bayesiana (afinada via Optuna) se encontra consolidada, garantindo m√°xima precis√£o.
* **`/notebooks/main.ipynb`**: O orquestrador visual. Respons√°vel por invocar os m√≥dulos, coordenar o *Hold-out* (80/20), gerar a interpretabilidade visual (SHAP) e exportar a submiss√£o final.

---

## ‚öôÔ∏è 3. Como Executar o Pipeline (O Caminho Metodol√≥gico)

A execu√ß√£o no ficheiro `main.ipynb` obedece a um rigoroso protocolo de valida√ß√£o para evitar qualquer risco de *Data Leakage* e garantir a adequa√ß√£o da m√©trica principal (*Recall*).

### Fase 1: Valida√ß√£o Rigorosa (An√°lise Cega)
1. **Segrega√ß√£o:** O *script* isola estrategicamente 20% dos dados.
2. **Treino e Isolamento:** O *Scaler* e o Meta-Modelo aprendem **exclusivamente** com a fatia de 80%.
3. **M√©tricas de Neg√≥cio:** Avaliamos a performance com foco na redu√ß√£o de Falsos Negativos (maximiza√ß√£o do *Recall*), gerando a Matriz de Confus√£o e os gr√°ficos SHAP de forma transparente e audit√°vel.

### Fase 2: Gera√ß√£o do Artefato Final (A Estrat√©gia Anti-Overfitting)
1. **Decis√£o Arquitet√≥nica:** Diferente de abordagens amadoras que for√ßam um re-treino com 100% dos dados para enviesar o *score* p√∫blico, este *script* preserva a intelig√™ncia do modelo validado nos 80%. 
2. **Robustez Final:** O *Stacking Ensemble* gera as probabilidades para o ficheiro `test.csv` da competi√ß√£o com base nesta aprendizagem generalista e imaculada.

---

##  4. Guia de Submiss√£o no Kaggle

A estrat√©gia de submiss√£o gerada por este c√≥digo blinda a solu√ß√£o contra as surpresas metodol√≥gicas e as quedas abruptas de classifica√ß√£o no fecho da avalia√ß√£o:

* **O Escudo do Private Leaderboard:** O ficheiro `submission.csv` gerado √© suportado pela valida√ß√£o *Hold-out*. Foi esta exata configura√ß√£o que cravou o cobi√ßado ROC-AUC de **0.99090** no *Public Leaderboard*. Ao mantermos a disciplina de n√£o sobreajustar o modelo com a totalidade dos dados, garantimos que ele possui a m√°xima resili√™ncia para lidar com os 70% de dados de teste que o Kaggle mant√©m ocultos.

---

##  5. Infer√™ncia em Novos Dados (Escalabilidade da Solu√ß√£o)

Se desejares contribuir ou utilizar este modelo para inferir a probabilidade de fraude em **novas transa√ß√µes** (simulando um sistema financeiro em tempo real), basta importar os m√≥dulos pr√©-treinados:

```python
from src.preprocessing import feature_engineering

# Supondo que 'novos_dados_df' √© um DataFrame com transa√ß√µes financeiras recentes
# Aplicamos as mesmas transforma√ß√µes usando estritamente o scaler j√° treinado
dados_prontos = feature_engineering(
    novos_dados_df, 
    scaler=scaler_treinado, 
    is_train=False
)

# O modelo devolve a probabilidade exata (ex: 0.87 -> 87% de probabilidade de anomalia)
probabilidade_fraude = model.predict_proba(dados_prontos)[:, 1]
```
Esta facilidade de adapta√ß√£o traduz os resultados acad√©micos numa funcionalidade t√©cnica de excel√™ncia, pronta a ser acoplada a servi√ßos na nuvem (Cloud/API).
