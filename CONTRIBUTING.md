# ðŸ¤ Guia de ContribuiÃ§Ã£o, Reprodutibilidade e InferÃªncia

Bem-vindo ao manual tÃ©cnico e arquitetÃ³nico da minha soluÃ§Ã£o para a deteÃ§Ã£o de fraudes financeiras. Concebi este guia com um objetivo claro: garantir **100% de reprodutibilidade** e demonstrar que o projeto transcende a simples criaÃ§Ã£o de um modelo de *Machine Learning*. 

Aqui, detalho como apliquei boas prÃ¡ticas de engenharia de *software*, segregaÃ§Ã£o rigorosa de dados e um *pipeline* preparado nÃ£o apenas para o Kaggle, mas para inferÃªncia de novos dados num ambiente de produÃ§Ã£o real.

---

## ðŸ› ï¸ 1. ConfiguraÃ§Ã£o do Ambiente Local (Reprodutibilidade: 5/5)

Para evitar os clÃ¡ssicos problemas de dependÃªncias cruzadas e garantir que a aplicaÃ§Ã£o funciona perfeitamente em qualquer mÃ¡quina, estruturei o projeto com recurso a ambientes virtuais isolados.

**Passo 1: Clonar o repositÃ³rio**
```bash
git clone [https://github.com/willianrupert/teste.git](https://github.com/willianrupert/teste.git)
cd teste
```

**Passo 2: Criar e ativar o ambiente virtual**
A utilizaÃ§Ã£o de um *venv* garante que as versÃµes do XGBoost, CatBoost e SHAP nÃ£o entram em conflito com as bibliotecas do teu sistema.
```bash
# Em sistemas Linux/macOS:
python3 -m venv venv
source venv/bin/activate

# Em sistemas Windows:
python -m venv venv
venv\Scripts\activate
```

**Passo 3: Instalar as dependÃªncias rigorosamente mapeadas**
```bash
pip install -r requirements.txt
```

---

## ðŸ“ 2. Arquitetura e SegregaÃ§Ã£o de Ficheiros (Qualidade de Engenharia: 5/5)

A separaÃ§Ã£o de responsabilidades Ã© o coraÃ§Ã£o deste projeto. Evitei deliberadamente *notebooks* monolÃ­ticos, optando por uma estrutura modular digna de um sistema *end-to-end*.

* **`/data/`**: Pasta reservada aos ficheiros `train.csv` e `test.csv`. *(Nota: Esta pasta estÃ¡ no `.gitignore` para proteger a integridade dos dados originais e cumprir regras de privacidade).*
* **`/src/`**: O motor da aplicaÃ§Ã£o.
  * `preprocessing.py`: Centraliza as transformaÃ§Ãµes nÃ£o-lineares, o *RobustScaler* e a deteÃ§Ã£o de anomalias (*Isolation Forest*). Esta modularidade permite que a mesma transformaÃ§Ã£o seja aplicada a dados futuros de inferÃªncia sem reescrever cÃ³digo.
  * `model.py`: Encapsula a arquitetura complexa do *Stacking Ensemble*. Ã‰ aqui que a otimizaÃ§Ã£o de hiperparÃ¢metros se encontra consolidada, garantindo mÃ¡xima precisÃ£o.
* **`/notebooks/main.ipynb`**: O orquestrador visual. ResponsÃ¡vel por invocar os mÃ³dulos, coordenar o *Hold-out* (80/20), gerar a interpretabilidade visual (SHAP) e exportar as submissÃµes finais.

---

## âš™ï¸ 3. Como Executar o Pipeline (O Caminho MetodolÃ³gico)

A execuÃ§Ã£o no ficheiro `main.ipynb` foi dividida em duas fases metodolÃ³gicas estritas para evitar qualquer risco de *Data Leakage* e garantir a adequaÃ§Ã£o da mÃ©trica principal (*Recall*).

### Fase 1: ValidaÃ§Ã£o Rigorosa (AnÃ¡lise Cega)
1. **SegregaÃ§Ã£o:** O *script* isola 20% dos dados.
2. **Treino e Isolamento:** O *Scaler* e o *Isolation Forest* aprendem **exclusivamente** com a fatia de 80%.
3. **MÃ©tricas de NegÃ³cio:** Avaliamos a performance com foco na reduÃ§Ã£o de Falsos Negativos (maximizaÃ§Ã£o do *Recall*), gerando a Matriz de ConfusÃ£o e os grÃ¡ficos SHAP de forma transparente e auditÃ¡vel.

### Fase 2: InferÃªncia e ProduÃ§Ã£o (O Treino Definitivo)
1. **ExpansÃ£o de Conhecimento:** Uma vez validada a arquitetura sem *overfitting*, o *script* ignora a divisÃ£o de 80/20 e aplica a funÃ§Ã£o `feature_engineering` sobre **100% dos dados de treino**.
2. **Robustez Final:** O meta-modelo (RegressÃ£o LogÃ­stica com forte regularizaÃ§Ã£o L2, $C=0.1$) Ã© treinado para consolidar a aprendizagem e prever o ficheiro `test.csv` da competiÃ§Ã£o.

---

## ðŸš€ 4. Guia de SubmissÃ£o no Kaggle

Para maximizar a pontuaÃ§Ã£o na competiÃ§Ã£o, o *script* gera os ficheiros CSV automaticamente. A minha estratÃ©gia de submissÃ£o dupla blinda a soluÃ§Ã£o contra surpresas no fecho da avaliaÃ§Ã£o:

1. **SubmissÃ£o A (O CampeÃ£o do Public Leaderboard):** O ficheiro gerado pelo modelo validado em 80% dos dados. Garante o pico estatÃ­stico visÃ­vel atualmente.
2. **SubmissÃ£o B (O Escudo do Private Leaderboard):** O ficheiro `submission_vaga_producao.csv`, treinado com 100% dos dados. Esta submissÃ£o possui a mÃ¡xima capacidade de generalizaÃ§Ã£o desenvolvida na aplicaÃ§Ã£o, pronta para absorver variaÃ§Ãµes ocultas nos dados de teste finais sem colapsar.

---

## ðŸ› ï¸ 5. InferÃªncia em Novos Dados (Escalabilidade da SoluÃ§Ã£o)

Se desejares contribuir ou utilizar este modelo para inferir a probabilidade de fraude em **novas transaÃ§Ãµes** (simulando um sistema financeiro em tempo real), basta importar os mÃ³dulos prÃ©-treinados:

```python
from src.preprocessing import feature_engineering

# Supondo que 'novos_dados_df' Ã© um DataFrame com transaÃ§Ãµes recentes
# Aplicamos as mesmas transformaÃ§Ãµes usando o scaler e iso_forest jÃ¡ treinados
dados_prontos = feature_engineering(
    novos_dados_df, 
    scaler=scaler_treinado, 
    iso_forest=iso_treinado, 
    is_train=False
)

# O modelo devolve a probabilidade exata (ex: 0.87 -> 87% de probabilidade de anomalia)
probabilidade_fraude = model.predict_proba(dados_prontos)[:, 1]
