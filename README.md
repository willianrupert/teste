#  Detec√ß√£o de Fraudes em Cart√µes de Cr√©dito: Uma Abordagem Robusta com Stacking Ensembles e XAI

**Autor:** Willian Rupert (Estudante de Ci√™ncia da Computa√ß√£o - CIn/UFPE)  
**Objetivo:** Desenvolvimento de um modelo de *Machine Learning* de alta precis√£o para o desafio de classifica√ß√£o de transa√ß√µes financeiras fraudulentas, priorizando o rigor metodol√≥gico, otimiza√ß√£o Bayesiana, a reprodutibilidade e a explicabilidade voltada para o neg√≥cio.

---

##  1. O Problema e a Vis√£o de Neg√≥cio (Adequa√ß√£o da M√©trica)

Em sistemas de pagamentos reais, lidamos com um cen√°rio de **extremo desbalanceamento de classes**, onde as fraudes representam uma fra√ß√£o min√∫scula das transa√ß√µes di√°rias. 

Ao analisar o hist√≥rico de avalia√ß√µes de modelos preditivos em cen√°rios cr√≠ticos, observei que muitos profissionais focam cegamente no F1-Score ou na Acur√°cia. A minha modelagem, contudo, foi constru√≠da com foco no impacto de neg√≥cio: **a prioridade financeira √© o Recall (Sensibilidade)**. 

Aprovar uma fraude (Falso Negativo) tem um custo de estorno devastador. Assim, a arquitetura foi desenhada para maximizar a captura de fraudes reais, ajustando o limiar de decis√£o (*threshold* de `0.3`) para manter os Falsos Positivos em um volume operacionalmente aceit√°vel para as equipes de an√°lise manual.

---

##  2. Rigor Metodol√≥gico e Preven√ß√£o de Data Leakage

Para garantir que a performance n√£o fosse fruto de memoriza√ß√£o, adotei uma pol√≠tica inegoci√°vel de segrega√ß√£o:
* **Hold-out Validation (80/20):** Separei 20% dos dados como um conjunto cego. Todas as decis√µes de arquitetura e gera√ß√£o de m√©tricas foram tomadas baseadas **apenas** nos 80% do treino.
* **Isolamento de Transformadores:** O algoritmo de padroniza√ß√£o (`RobustScaler`) foi ajustado (`.fit()`) unicamente nos dados de treino. Os par√¢metros de escala aprendidos foram ent√£o aplicados de forma est√°tica (`.transform()`) aos dados de teste.

---

##  3. A Evolu√ß√£o da Arquitetura (A Rota do 0.99090)

O desenvolvimento deste modelo foi um processo cient√≠fico e iterativo, registrado ao longo de 7 submiss√µes na plataforma Kaggle.

### Fase 1: Rota√ß√£o Geom√©trica (Feature Engineering)
As √°rvores de decis√£o sofrem limita√ß√µes ao lidar com fronteiras de classe diagonais, pois s√≥ realizam particionamentos ortogonais. Para contornar isso, criei vari√°veis que efetuam uma proje√ß√£o matem√°tica do espa√ßo:
1. **Intera√ß√µes Otimizadas:** A diferen√ßa alg√©brica `V4 - V14` e a soma `V14 + V12` rotacionaram o plano, permitindo que as √°rvores isolassem a fraude com precis√£o cir√∫rgica sem precisarem gerar ramifica√ß√µes profundas (evitando *overfitting*).
2. **Tempo e Logaritmo:** `Time` foi decomposto em ondas (seno/cosseno) para capturar a sazonalidade, e `Amount` recebeu transforma√ß√£o logar√≠tmica.

### Fase 2: Otimiza√ß√£o Bayesiana (Optuna)
Em vez de depender de chutes manuais, integrei o \textit{framework} **Optuna**. O algoritmo utilizou estimadores de Parzen estruturados em √°rvore para varrer o hiper-espa√ßo e encontrar as engrenagens perfeitas do modelo (como o `learning_rate=0.09` para o XGBoost).

### Fase 3: Stacking Ensemble Calibrado e o Public Leaderboard
A arquitetura final √© composta por:
* **N√≠vel 0:** XGBoost, LightGBM e CatBoost otimizados e penalizando severamente a classe majorit√°ria.
* **N√≠vel 1 (O Juiz):** Uma Regress√£o Log√≠stica operando com `class_weight='balanced'`. O meta-modelo recebe as probabilidades brutas das √°rvores e as calibra linearmente.

**A Decis√£o sobre o Conjunto de Treino:** Durante a competi√ß√£o, testei re-treinar a rede com 100% dos dados para for√ßar o *score*. Contudo, essa pr√°tica gerou flutua√ß√µes e perda de estabilidade ($\approx 0.985$). Tomei a decis√£o arquitetural consciente de **submeter a vers√£o treinada estritamente no conjunto de 80%**. O Kaggle avalia publicamente apenas 30% dos dados. Submeter o modelo estabilizado na valida√ß√£o local √© a prova m√°xima de maturidade para evitar o catastr√≥fico *overfitting* da m√©trica p√∫blica e garantir o sucesso na avalia√ß√£o privada (70% ocultos). Com esta disciplina, **cravei o pico absoluto de 0.99090**.

---

##  4. Explicabilidade e Tradu√ß√£o para o Neg√≥cio (XAI)

Modelos "caixa-preta" s√£o vetados em ambientes regulados. A arquitetura foi desmistificada utilizando a biblioteca **SHAP (SHapley Additive exPlanations)**.

* **Vis√£o Macro (Global):** Os gr√°ficos comprovam a efic√°cia da nossa engenharia. As intera√ß√µes criadas (`V4_minus_V14`) brilham de forma un√¢nime como os fatores mais determinantes do modelo.

<div align="center">
  <img src="notebooks/shap_summary.png" alt="SHAP Summary - Import√¢ncia Global das Features" width="700"/>
</div>

<br>

* **Vis√£o Micro (Local - Auditoria):** O *Waterfall* detalha a anatomia de uma fraude interceptada. Conseguimos explicar ao neg√≥cio exatamente os "pesos e pontua√ß√µes" somados pela IA em tempo real para bloquear um cart√£o.

<div align="center">
  <img src="notebooks/shap_local_fraude.png" alt="SHAP Waterfall - Explicabilidade Local de uma Fraude" width="700"/>
</div>

<br>

* **Impacto Operacional (Matriz de Confus√£o):** O modelo √© equilibrado. Restringe rigorosamente as anomalias, mas aprova tranquilamente as transa√ß√µes saud√°veis, limitando os Falsos Positivos a uma √≠nfima taxa de $\approx 0.77\%$.

<div align="center">
  <img src="notebooks/matriz_confusao.png" alt="Matriz de Confus√£o - Equil√≠brio de Falsos Positivos e Negativos" width="500"/>
</div>

---

##  5. Qualidade de Engenharia e Reprodutibilidade

A base de c√≥digo foi estruturada pensando em um *deploy* corporativo e n√£o apenas na competi√ß√£o:
* **`src/preprocessing.py`:** Encapsula, de forma estanque, todas as regras de normaliza√ß√£o e transforma√ß√µes alg√©bricas, desenhado para receber novas linhas de dados no futuro.
* **`src/model.py`:** O construtor do *Stacking Ensemble*, facilitando itera√ß√µes, substitui√ß√µes e auditoria dos estimadores base.
* **`notebooks/main.ipynb`:** O orquestrador limpo e linear que narra o fluxo da execu√ß√£o de ponta a ponta.

---

## üèÅ 6. Conclus√£o

Este reposit√≥rio mostra que a a robustez em *Machine Learning* reside na intelig√™ncia matem√°tica aplicada aos dados e na disciplina metodol√≥gica. O modelo resultante atinge uma precis√£o √≠mpar (ROC-AUC de 0.99090), √© audit√°vel, robusto contra flutua√ß√µes e perfeitamente dimensionado para salvar uma opera√ß√£o financeira real das perdas di√°rias por estorno.
