# üõ°Ô∏è Detec√ß√£o de Fraudes em Cart√µes de Cr√©dito: Uma Abordagem Robusta com Stacking Ensembles e XAI

**Autor:** Willian Rupert (Estudante de Ci√™ncia da Computa√ß√£o - CIn/UFPE)  
**Objetivo:** Desenvolvimento de um modelo de *Machine Learning* de alta precis√£o para o desafio de classifica√ß√£o de transa√ß√µes financeiras fraudulentas, priorizando o rigor metodol√≥gico, a reprodutibilidade e a explicabilidade voltada para o neg√≥cio.

---

## üéØ 1. O Problema e a Vis√£o de Neg√≥cio (Adequa√ß√£o da M√©trica)

Em sistemas de pagamentos reais, lidamos com um cen√°rio de **extremo desbalanceamento de classes**, onde as fraudes representam uma fra√ß√£o min√∫scula das transa√ß√µes di√°rias. 

Ao analisar o hist√≥rico de avalia√ß√µes de modelos preditivos em cen√°rios cr√≠ticos (como sa√∫de e finan√ßas), observei que muitos cientistas de dados cometem o erro de focar na m√©trica F1-Score ou na Acur√°cia. No entanto, a minha modelagem foi constru√≠da com os olhos estritamente voltados para o impacto de neg√≥cio: **a prioridade financeira √© o Recall (Sensibilidade)**. 

Aprovar uma transa√ß√£o fraudulenta (Falso Negativo) tem um custo de estorno e perda de credibilidade devastador. Portanto, a arquitetura deste projeto foi desenhada para maximizar a captura de fraudes reais, ajustando os limiares de decis√£o (*thresholds*) para manter os Falsos Positivos (clientes leg√≠timos bloqueados) em um volume operacionalmente aceit√°vel para uma equipe de an√°lise manual.

---

## üß™ 2. Rigor Metodol√≥gico e Preven√ß√£o de Data Leakage

Para garantir que os resultados obtidos n√£o fossem fruto de *overfitting* ou memoriza√ß√£o de dados, adotei uma pol√≠tica estrita de segrega√ß√£o:
* **Hold-out Validation (80/20):** Separei 20% dos dados como um conjunto cego. Todas as decis√µes de arquitetura, otimiza√ß√£o e gera√ß√£o de m√©tricas de valida√ß√£o foram feitas olhando **apenas** para o conjunto de treino de 80%.
* **Isolamento de Transformadores:** Algoritmos como o `RobustScaler` e o `IsolationForest` foram ajustados (`.fit()`) exclusivamente nos dados de treino. Seus par√¢metros aprendidos foram ent√£o aplicados (`.transform()`) aos dados de valida√ß√£o e teste, eliminando qualquer possibilidade de vazamento de informa√ß√µes do futuro (*Data Leakage*).

---

## üöÄ 3. A Evolu√ß√£o da Arquitetura (Minha Jornada de 7 Submiss√µes)

O desenvolvimento deste modelo n√£o foi uma tentativa de for√ßa bruta algor√≠tmica, mas um processo cient√≠fico e iterativo. Ao longo de 7 submiss√µes na plataforma Kaggle, evolu√≠ a solu√ß√£o desde a an√°lise explorat√≥ria at√© um *ensemble* de estado da arte.

### Fase 1: An√°lise Explorat√≥ria e Feature Engineering (Sinal Supervisionado)
Antes de testar modelos complexos, foquei em extrair o sinal matem√°tico oculto na base de dados. Atrav√©s de correla√ß√µes emp√≠ricas, percebi que algumas vari√°veis anonimizadas escondiam comportamentos geom√©tricos valiosos:
1. **Intera√ß√µes Matem√°ticas Otimizadas:** A cria√ß√£o da diferen√ßa alg√©brica `V4 - V14` e da soma `V14 + V12` amplificou o sinal das fraudes de forma dr√°stica, criando separadores de classe muito mais fortes do que as vari√°veis isoladas.
2. **Tratamento do Tempo e Valor:** A vari√°vel `Time` foi decomposta em componentes c√≠clicas (seno e cosseno) para capturar a sazonalidade di√°ria das fraudes. A vari√°vel `Amount` sofreu uma transforma√ß√£o logar√≠tmica para mitigar o peso de *outliers* extremos.

### Fase 2: Otimiza√ß√£o de Hiperpar√¢metros e a Conquista do 0.99090
Para evitar a simplicidade e extrair o m√°ximo de performance, utilizei otimiza√ß√£o Bayesiana (**Optuna**) para encontrar a configura√ß√£o ideal de um **Stacking Ensemble**:
* **N√≠vel 0 (Diversidade de Aprendizado):** Integrei os tr√™s algoritmos de *Gradient Boosting* mais poderosos da literatura: **XGBoost, LightGBM e CatBoost**. Cada um foi configurado com uma baixa taxa de aprendizagem (`learning_rate=0.05`) para converg√™ncia suave e pesados rigorosamente para penalizar a classe majorit√°ria (`scale_pos_weight=89.8`).
* **N√≠vel 1 (O Juiz Conservador):** Para consolidar as previs√µes do N√≠vel 0, utilizei uma Regress√£o Log√≠stica. O grande diferencial aqui foi a aplica√ß√£o de uma **forte regulariza√ß√£o L2 ($C=0.1$)**, que blindou o meta-modelo contra o v√≠cio nas √°rvores de decis√£o.
* **Resultado:** Validado estritamente no *Hold-out* de 20%, este modelo cravou **0.99090 de ROC-AUC** no *Public Leaderboard* do Kaggle.

### Fase 3: Detec√ß√£o N√£o-Supervisionada e a Estrat√©gia de Produ√ß√£o
Fraudes financeiras s√£o mut√°veis. Para proteger o modelo contra padr√µes de ataque in√©ditos (*Zero-Day Fraud*), implementei a terceira fase da arquitetura:
* **Isolation Forest:** Um modelo n√£o-supervisionado treinado paralelamente para calcular um *Anomaly Score* baseado na densidade de isolamento estat√≠stico das transa√ß√µes.
* **O Treino Definitivo (100% dos Dados):** Compreendendo que o *Public Leaderboard* avalia apenas $\approx 30\%$ dos dados de teste, tomei a decis√£o arquitetural de re-treinar a vers√£o final do modelo com **100% dos dados de treino originais**. Esta estrat√©gia abdica do *overfitting* nas m√©tricas p√∫blicas em favor de uma generaliza√ß√£o robusta e definitiva para a avalia√ß√£o privada (*Private Leaderboard*).

---

## üß† 4. Tradu√ß√£o de Resultados e Explicabilidade (XAI)

Na ind√∫stria de pagamentos, um modelo que atua como "caixa-preta" √© inaceit√°vel devido a exig√™ncias regulat√≥rias. Para solucionar isso, integrei a Teoria dos Jogos atrav√©s da biblioteca **SHAP (SHapley Additive exPlanations)**.

* **Vis√£o Macro (Global):** Os gr√°ficos *SHAP Summary* confirmaram a efic√°cia da Engenharia de Caracter√≠sticas. As intera√ß√µes matem√°ticas manuais (`V4_minus_V14` e `V14_V12_sum`) assumiram as posi√ß√µes de lideran√ßa no ranqueamento de import√¢ncia, provando que o poder do modelo veio da manipula√ß√£o inteligente dos dados, e n√£o do acaso.

<div align="center">
  <img src="notebooks/shap_summary.png" alt="SHAP Summary - Import√¢ncia Global das Features" width="700"/>
</div>

<br>

* **Vis√£o Micro (Local):** Utilizei o *SHAP Waterfall* para destrinchar casos individuais de fraude. O sistema agora √© capaz de emitir um relat√≥rio explicando exatamente quantos pontos percentuais cada vari√°vel contribuiu para o bloqueio de uma transa√ß√£o espec√≠fica, entregando uma ferramenta pronta para as equipes de Preven√ß√£o a Fraude.

<div align="center">
  <img src="notebooks/shap_local_fraude.png" alt="SHAP Waterfall - Explicabilidade Local de uma Fraude" width="700"/>
</div>

<br>

* **Impacto Operacional (Matriz de Confus√£o):** Para coroar a tradu√ß√£o para o neg√≥cio, a matriz de confus√£o demonstra o excelente equil√≠brio alcan√ßado. O modelo restringe severamente os Falsos Positivos, permitindo que a opera√ß√£o de aprova√ß√£o de cart√µes flua de forma saud√°vel e sem fric√ß√µes desnecess√°rias para os clientes leg√≠timos, ao passo que garante a captura implac√°vel das anomalias.

<div align="center">
  <img src="notebooks/matriz_confusao.png" alt="Matriz de Confus√£o - Equil√≠brio de Falsos Positivos e Negativos" width="500"/>
</div>

---

## üèóÔ∏è 5. Qualidade de Engenharia e Reprodutibilidade

O c√≥digo foi constru√≠do seguindo rigorosos padr√µes de engenharia de software, garantindo modularidade e f√°cil implanta√ß√£o em sistemas legados:
* **`src/preprocessing.py`:** Isola toda a l√≥gica de limpeza, transforma√ß√£o c√≠clica, normaliza√ß√£o matem√°tica e infer√™ncia do *Isolation Forest*.
* **`src/model.py`:** Encapsula a arquitetura complexa do *Stacking Ensemble*, facilitando testes unit√°rios e a substitui√ß√£o de algoritmos base.
* **`notebooks/main.ipynb`:** O orquestrador limpo, respons√°vel exclusivamente pelo fluxo de dados, visualiza√ß√£o (Matriz de Confus√£o e SHAP) e gera√ß√£o do artefato final (`.csv`).

---

## üèÅ 6. Conclus√£o

Este projeto prova que a resolu√ß√£o de problemas complexos de *Machine Learning* n√£o depende apenas de importar bibliotecas pesadas, mas sim de uma profunda compreens√£o matem√°tica dos dados aliada √† vis√£o de neg√≥cio. A solu√ß√£o apresentada vai muito al√©m de uma simples submiss√£o no Kaggle: ela entrega um *pipeline end-to-end* resiliente, otimizado metodologicamente, audit√°vel por humanos (SHAP) e focado na redu√ß√£o real de perdas financeiras operacionais.
